# ğŸ“˜ Bielik Ethnographic Benchmark

Testowanie polskich modeli jÄ™zykowych w kontekÅ›cie wiedzy etnologicznej i kultury lokalnej.

---

## ğŸ” Cel projektu

Stworzenie benchmarku porÃ³wnujÄ…cego jakoÅ›Ä‡ odpowiedzi rÃ³Å¼nych modeli jÄ™zykowych (np. GPT-4, Gemini, Bielik) na pytania zamkniÄ™te z zakresu etnologii i historii spoÅ‚ecznej w Polsce.

---

## ğŸ—‚ï¸ Struktura repozytorium

```
â”œâ”€â”€ benchmark_test_llm_main.py    # GÅ‚Ã³wny skrypt uruchamiajÄ…cy testowanie
â”œâ”€â”€ results/                      # Folder z odpowiedziami modeli i statystykami
â”œâ”€â”€ test_files/                   # PrzykÅ‚adowe pliki testowe (CSV/XLSX)
â”œâ”€â”€ moduÅ‚y/                       # Folder z moduÅ‚ami funkcjonalnymi
â”‚   â”œâ”€â”€ dataset_loader.py         # Wczytywanie danych testowych
â”‚   â”œâ”€â”€ llm_connector.py          # ObsÅ‚uga komunikacji z modelami (lokalnie/API)
â”‚   â”œâ”€â”€ response_saver.py         # Zapis wynikÃ³w do JSON/CSV
â”‚   â””â”€â”€ utils.py                  # Funkcje pomocnicze
â”œâ”€â”€ _natalia_prototyp/           # Archiwum pierwszej wersji benchmarku
â”œâ”€â”€ requirements.txt             # Lista wymaganych bibliotek
â””â”€â”€ README.md                    # Niniejszy plik
```

---

## â–¶ï¸ Uruchamianie benchmarku

### Wersja CLI:

```bash
python main.py \
  --llm="bielik-chat" \
  --llm-name="Bielik" \
  --test="./test_files/test.xlsx" \
  --results="./results/bielik.json" \
  --api="local" \
  --interval=0
```

### Wymagane argumenty:

- `--llm` â€“ unikalny identyfikator modelu
- `--llm-name` â€“ przyjazna nazwa modelu
- `--test` â€“ Å›cieÅ¼ka do pliku testowego (`.csv` lub `.xlsx`)

### Opcjonalne:

- `--results` â€“ Å›cieÅ¼ka do pliku wyjÅ›ciowego
- `--api` â€“ typ API (`local`, `openAI`, `vllm`)
- `--url`, `--key` â€“ jeÅ›li uÅ¼ywasz modelu przez API (np. OpenAI)
- `--interval` â€“ opÃ³Åºnienie miÄ™dzy zapytaniami

---

## ğŸ§ª Dane wejÅ›ciowe (testy)

Plik testowy powinien zawieraÄ‡ kolumny:

- `Pytanie`
- `A`, `B`, `C`, `D` â€“ moÅ¼liwe odpowiedzi
- `Pozycja` â€“ poprawna odpowiedÅº (litera A-D)
- `Domena`, `Kategoria`, `Tagi`

---

## ğŸ“¤ Dane wyjÅ›ciowe

Skrypt zapisuje dwa pliki:

1. `results/model.jsonl` â€“ lista odpowiedzi modelu na kaÅ¼de pytanie
2. `output.json` â€“ podsumowanie (liczba pytaÅ„, poprawnych odpowiedzi itd.)

---

## ğŸ”§ Wymagania

- Python 3.9+
- Biblioteki: `pandas`, `openai`, `google-generativeai`, `argparse`, `dotenv`

Instalacja:

```bash
pip install -r requirements.txt
```

---

## ğŸ‘¥ ZespÃ³Å‚

- Natalia Nadolna (https://github.com/NataliaNadolna)
- Revi (https://github.com/ReviIsCoding)
- Krzysztof Raszczuk â€“ konsultacje merytoryczne

---
