# ğŸ“˜ Bielik Ethnographic Benchmark

Testowanie polskich modeli jÄ™zykowych w kontekÅ›cie wiedzy etnologicznej i kultury lokalnej.

---

## ğŸ” Cel projektu

Stworzenie benchmarku porÃ³wnujÄ…cego jakoÅ›Ä‡ odpowiedzi rÃ³Å¼nych modeli jÄ™zykowych (np. GPT-4, Gemini, Bielik) na pytania zamkniÄ™te z zakresu etnologii i historii spoÅ‚ecznej w Polsce.

---

## ğŸ—‚ï¸ Struktura repozytorium

```
â”œâ”€â”€ benchmark_test_llm_main.py    # GÅ‚Ã³wny skrypt uruchamiajÄ…cy testowanie
â”œâ”€â”€ results/                      # Folder z odpowiedziami modeli i statystykami
â”œâ”€â”€ tests/                        # Folder z plikami testÃ³w jednostkowych i integracyjnych
â”œâ”€â”€ moduÅ‚y/                       # Folder z moduÅ‚ami funkcjonalnymi
â”‚   â”œâ”€â”€ dataset_loader.py         # Wczytywanie danych testowych z pliku CSV/XLSX
â”‚   â”œâ”€â”€ llm_connector.py          # ObsÅ‚uga komunikacji z modelami (lokalnie/API)
â”‚   â”œâ”€â”€ response_saver.py         # Zapis wynikÃ³w do JSON/CSV
â”‚   â””â”€â”€ utils.py                  # Funkcje pomocnicze (parsowanie outputu, budowa promptu)
â”œâ”€â”€ _natalia_prototyp/           # Archiwum pierwszej wersji benchmarku
â”œâ”€â”€ requirements.txt             # Lista wymaganych bibliotek
â””â”€â”€ README.md                    # Niniejszy plik
```

---

## â–¶ï¸ Uruchamianie benchmarku - generowanie odpowiedzi

### Wersja CLI:

```bash
python benchmark_test_llm_main.py \
  --llm="bielik-chat" \
  --llm-name="Bielik" \
  --test="./test_files/test.xlsx" \
  --results="./results/bielik.json" \
  --api="local" \
  --interval=0
```
Po uruchomieniu benchmarku zapisywana jest lista surowych odpowiedzi modelu. 
PorÃ³wnanie odpowiedzi z prawidÅ‚owymi i statystyki sÄ… generowane w osobnym kroku (skrypt `benchmark_merge_results.py`).

### Wymagane argumenty:

- `--llm` â€“ unikalny identyfikator modelu
- `--llm-name` â€“ przyjazna nazwa modelu
- `--test` â€“ Å›cieÅ¼ka do pliku testowego (`.csv` lub `.xlsx`)

### Opcjonalne:

- `--results` â€“ Å›cieÅ¼ka do pliku wyjÅ›ciowego
- `--api` â€“ typ API (`local`, `openAI`, `vllm`)
- `--url`, `--key` â€“ jeÅ›li uÅ¼ywasz modelu przez API (np. OpenAI)
- `--interval` â€“ opÃ³Åºnienie miÄ™dzy zapytaniami

---

## ğŸ§ª Dane wejÅ›ciowe (testy)

Plik testowy powinien zawieraÄ‡ kolumny:

- `Pytanie`
- `A`, `B`, `C`, `D` â€“ moÅ¼liwe odpowiedzi
- `Pozycja` â€“ poprawna odpowiedÅº (litera A-D)
- `Domena`, `Kategoria`, `Tagi`

---

## ğŸ“¤ Dane wyjÅ›ciowe

Po uruchomieniu benchmarku zapisuje:

- `results/model_raw.json` â€“ surowe odpowiedzi modelu na kaÅ¼de pytanie (bez oceny)
- (w kolejnym kroku) `results/model_summary.json` â€“ podsumowanie ocen (tworzone osobnym skryptem)

---

## ğŸ“ Tworzenie promptu i przetwarzanie odpowiedzi

- Prompt budowany jest na podstawie kaÅ¼dego wiersza z pliku testowego, zgodnie z szablonem zdefiniowanym w `utils.py` (`PROMPT_TEMPLATE`).
- Odpowiedzi modelu sÄ… parsowane funkcjÄ… `parse_output()` z `utils.py` i zapisywane w surowej formie do pliku JSON przez `response_saver.py`.
- Ocena poprawnoÅ›ci i podsumowanie wynikÃ³w odbywa siÄ™ w kolejnym kroku, przez osobny skrypt (`benchmark_merge_results.py`).

## ğŸ§ª Testowanie

Projekt zawiera dwa poziomy testÃ³w:

- **Testy jednostkowe** â€“ dotyczÄ… funkcji pomocniczych z moduÅ‚Ã³w w folderze `modules/` (np. `utils`, `dataset_loader`, `response_saver`). ZnajdujÄ… siÄ™ w `tests/unit/`.
- **Testy integracyjne** â€“ obejmujÄ… gÅ‚Ã³wny przebieg dziaÅ‚ania benchmarku:
  - `benchmark_test_llm_main.py` â€“ testowanie logiki uruchamiania modelu
  - `benchmark_merge_results.py` â€“ testowanie przetwarzania wynikÃ³w i generowania statystyk  
  ZnajdujÄ… siÄ™ w `tests/integration/`.

### ğŸ”„ Uruchamianie testÃ³w

Uruchomienie wszystkich testÃ³w w bash:
`pytest`

Tylko testy jednostkowe w bash:
`pytest tests/unit/`

Tylko testy integracyjne w bash:
`pytest tests/integration/`

## ğŸ”§ Wymagania

- Python 3.9+
- Biblioteki: `pandas`, `openai`, `google-generativeai`, `argparse`, `dotenv`

Instalacja:

```bash
pip install -r requirements.txt
```

---

## ğŸ‘¥ ZespÃ³Å‚

- Natalia Nadolna (https://github.com/NataliaNadolna)
- Anna ZieliÅ„ska (https://github.com/ReviIsCoding)
- Krzysztof Raszczuk â€“ konsultacje merytoryczne

---
